{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e10fb4",
   "metadata": {},
   "source": [
    "# Exporting a model for deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89ac622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60c46910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import window_generator as WindowGenerator\n",
    "from window_generator import WindowGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f5f1b",
   "metadata": {},
   "source": [
    "# Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e96e552e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>demand</th>\n",
       "      <th>emissions</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>58.82</td>\n",
       "      <td>24682</td>\n",
       "      <td>14467.2840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>58.23</td>\n",
       "      <td>24046</td>\n",
       "      <td>14173.8295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>51.95</td>\n",
       "      <td>22665</td>\n",
       "      <td>13198.0690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>47.27</td>\n",
       "      <td>21200</td>\n",
       "      <td>12510.7595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>45.49</td>\n",
       "      <td>20056</td>\n",
       "      <td>12203.7315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     price  demand   emissions\n",
       "data                                          \n",
       "2017-01-01 00:00:00  58.82   24682  14467.2840\n",
       "2017-01-01 01:00:00  58.23   24046  14173.8295\n",
       "2017-01-01 02:00:00  51.95   22665  13198.0690\n",
       "2017-01-01 03:00:00  47.27   21200  12510.7595\n",
       "2017-01-01 04:00:00  45.49   20056  12203.7315"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('extracted_data/csv/hour_merged.csv',\n",
    "                 parse_dates={'data': ['date', 'time']},\n",
    "                 infer_datetime_format=True,\n",
    "                 dayfirst=False,\n",
    "                 index_col='data'\n",
    "                )\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24f8e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select data from 2021\n",
    "df = df[int((len(df)*0.8)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c006609d",
   "metadata": {},
   "source": [
    "# Differencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2456c9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return pd.Series(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b23d4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_price = difference(df['price'])\n",
    "diff_emissions = difference(df['emissions'])\n",
    "diff_demand = difference(df['demand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbcee50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.Series([0.0])\n",
    "diff_price = s1.append(diff_price, ignore_index=True)\n",
    "diff_emissions = s1.append(diff_emissions, ignore_index=True)\n",
    "diff_demand = s1.append(diff_demand, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9db79c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = diff_price.values\n",
    "df['demand'] = diff_demand.values\n",
    "df['emissions'] = diff_emissions.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1120e7b",
   "metadata": {},
   "source": [
    "# Split into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6ed42fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80% for training and 20% for test\n",
    "n = len(df)\n",
    "train_df = df[0:int(n*0.8)]\n",
    "test_df = df[int(n*0.8):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29af97a1",
   "metadata": {},
   "source": [
    "# Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af1292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()\n",
    "\n",
    "train_df = (train_df - train_mean) / train_std\n",
    "test_df = (test_df - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf17b9",
   "metadata": {},
   "source": [
    "# Auxiliar methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec753688",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedBack(tf.keras.Model):\n",
    "    def __init__(self, units, out_steps):\n",
    "        super().__init__()\n",
    "        self.out_steps = out_steps\n",
    "        self.units = units\n",
    "\n",
    "        self.lstm_cell = tf.keras.layers.LSTMCell(units)\n",
    "        # Also wrap the LSTMCell in an RNN to simplify the `warmup` method.\n",
    "        self.lstm_rnn = tf.keras.layers.RNN(self.lstm_cell, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b779a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def warmup(self, inputs):\n",
    "    # Forma del input => (batch, time, features)\n",
    "    # Forma de x => (batch, lstm_units)\n",
    "    x, *state = self.lstm_rnn(inputs)\n",
    "    \n",
    "    # Forma de la predicción => (batch, features)\n",
    "    prediction = self.dense(x)\n",
    "    return prediction, state\n",
    "\n",
    "FeedBack.warmup = warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23400d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call(self, inputs, training=None):\n",
    "    # Usar un TensorArray para capturar unrolled outputs automáticamente\n",
    "    predictions = []\n",
    "    # Inicializar el estado de LSTM\n",
    "    prediction, state = self.warmup(inputs)\n",
    "    \n",
    "    # Insertar la primera predicción\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    # Ejecutar el resto de pasos de la predicción\n",
    "    for n in range(1, self.out_steps):\n",
    "        # Usar la última predicción como input\n",
    "        x = prediction\n",
    "        # Ejecutar un paso de lstm\n",
    "        x, state = self.lstm_cell(x, states=state, training=training)\n",
    "        # Convertir la salida de lstm en una predicción\n",
    "        prediction = self.dense(x)\n",
    "        # Añadir la predicción al output\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    # Forma de predictions => (time, batch, features)\n",
    "    predictions = tf.stack(predictions)\n",
    "    # Forma de predictions => (batch, time, features)\n",
    "    predictions = tf.transpose(predictions, [1,0,2])\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "FeedBack.call = call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc5bc68",
   "metadata": {},
   "source": [
    "# Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f2c2821",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 20\n",
    "patience = 4\n",
    "num_features=df.shape[1]\n",
    "OUT_STEPS = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcc82c30",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "217/217 [==============================] - 10s 34ms/step - loss: 0.6174 - root_mean_squared_error: 0.7858 - val_loss: 0.7522 - val_root_mean_squared_error: 0.8673\n",
      "Epoch 2/20\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 0.4649 - root_mean_squared_error: 0.6818 - val_loss: 0.8025 - val_root_mean_squared_error: 0.8958\n",
      "Epoch 3/20\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 0.3937 - root_mean_squared_error: 0.6274 - val_loss: 0.7033 - val_root_mean_squared_error: 0.8386\n",
      "Epoch 4/20\n",
      "217/217 [==============================] - 7s 33ms/step - loss: 0.3501 - root_mean_squared_error: 0.5917 - val_loss: 0.7379 - val_root_mean_squared_error: 0.8590\n",
      "Epoch 5/20\n",
      "217/217 [==============================] - 7s 32ms/step - loss: 0.3177 - root_mean_squared_error: 0.5637 - val_loss: 0.6578 - val_root_mean_squared_error: 0.8110\n",
      "Epoch 6/20\n",
      "217/217 [==============================] - 8s 35ms/step - loss: 0.2928 - root_mean_squared_error: 0.5411 - val_loss: 0.6774 - val_root_mean_squared_error: 0.8230\n",
      "Epoch 7/20\n",
      "217/217 [==============================] - 8s 37ms/step - loss: 0.2834 - root_mean_squared_error: 0.5323 - val_loss: 0.6312 - val_root_mean_squared_error: 0.7945\n",
      "Epoch 8/20\n",
      "217/217 [==============================] - 8s 38ms/step - loss: 0.2413 - root_mean_squared_error: 0.4913 - val_loss: 0.6240 - val_root_mean_squared_error: 0.7899\n",
      "Epoch 9/20\n",
      "217/217 [==============================] - 8s 38ms/step - loss: 0.2313 - root_mean_squared_error: 0.4810 - val_loss: 0.6436 - val_root_mean_squared_error: 0.8023\n",
      "Epoch 10/20\n",
      "217/217 [==============================] - 8s 38ms/step - loss: 0.2262 - root_mean_squared_error: 0.4756 - val_loss: 0.6112 - val_root_mean_squared_error: 0.7818\n",
      "Epoch 11/20\n",
      "217/217 [==============================] - 8s 38ms/step - loss: 0.2085 - root_mean_squared_error: 0.4566 - val_loss: 0.6257 - val_root_mean_squared_error: 0.7910\n",
      "Epoch 12/20\n",
      "217/217 [==============================] - 8s 36ms/step - loss: 0.2141 - root_mean_squared_error: 0.4627 - val_loss: 0.6068 - val_root_mean_squared_error: 0.7790\n",
      "Epoch 13/20\n",
      "217/217 [==============================] - 8s 38ms/step - loss: 0.1991 - root_mean_squared_error: 0.4462 - val_loss: 0.6092 - val_root_mean_squared_error: 0.7805\n",
      "Epoch 14/20\n",
      "217/217 [==============================] - 8s 37ms/step - loss: 0.1910 - root_mean_squared_error: 0.4370 - val_loss: 0.6464 - val_root_mean_squared_error: 0.8040\n",
      "Epoch 15/20\n",
      "217/217 [==============================] - 8s 37ms/step - loss: 0.1850 - root_mean_squared_error: 0.4302 - val_loss: 0.6103 - val_root_mean_squared_error: 0.7812\n",
      "Epoch 16/20\n",
      "217/217 [==============================] - 8s 37ms/step - loss: 0.1761 - root_mean_squared_error: 0.4197 - val_loss: 0.6072 - val_root_mean_squared_error: 0.7792\n"
     ]
    }
   ],
   "source": [
    "feedback_model = FeedBack(units=128, out_steps=OUT_STEPS)\n",
    "    \n",
    "# Creating a Window\n",
    "window = WindowGenerator(input_width=48, label_width=OUT_STEPS, shift=OUT_STEPS, train_df=train_df, test_df=test_df)\n",
    "    \n",
    "example_window = tf.stack([np.array(train_df[:window.total_window_size]),\n",
    "                           np.array(train_df[100:100+window.total_window_size]),\n",
    "                           np.array(train_df[200:200+window.total_window_size])\n",
    "                          ])\n",
    "    \n",
    "example_inputs, example_labels = window.split_window(example_window)\n",
    "    \n",
    "window.example = example_inputs, example_labels\n",
    "    \n",
    "prediction, state = feedback_model.warmup(window.example[0])\n",
    "    \n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min')\n",
    "    \n",
    "feedback_model.compile(loss='MeanSquaredError',\n",
    "                 optimizer='adam',\n",
    "                 metrics=[tf.metrics.RootMeanSquaredError()])\n",
    "    \n",
    "# History\n",
    "history = feedback_model.fit(window.train, epochs=MAX_EPOCHS, validation_data = window.test, callbacks=[early_stopping])\n",
    "    \n",
    "loss, rmse = feedback_model.evaluate(window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f481391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "feedback_model.save('saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60a5fb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('saved_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30c04aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6071691513061523, 0.7792105674743652]\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.evaluate(window.test, verbose=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
